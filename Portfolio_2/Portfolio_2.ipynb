{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Portfolio 2\n",
    "\n",
    "|Name|Github|Kaggle|\n",
    "|----|------|------|\n",
    "|Henry Lau|HenryLau08|Henry Lau|\n",
    "|Mohamed Belaachir|mobelaachir|Mo Belaachir|\n",
    "|Jayden Debi-Tewari|Jaydendt1|jaydendt123|\n",
    "|Quincy Soerohardjo|quincysoerohardjo2002|Quincy Soerohardjo|\n",
    "|Mattias Aareleid|mattyonaize|Mattias Aareleid|\n",
    "\n",
    "## Table of Contents\n",
    "- [Data Overview](#data-overview)\n",
    "- [Exploratory Data Analysis](#exploratory-data-analysis)\n",
    "- [Modeling](#modeling)\n",
    "\n",
    "- [Results](#results)\n",
    "- [Conclusion & Advice](#conclusion--advice)\n",
    "- [Sources](#sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Libraries\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.fft import fft, ifft\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', index_col='date_hour')\n",
    "test = pd.read_csv('test.csv', index_col='date_hour')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 05:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 06:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 07:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 08:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 09:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     holiday  weathersit  temp   atemp   hum  windspeed  cnt\n",
       "date_hour                                                                   \n",
       "2011-01-01 00:00:00        0           1  0.24  0.2879  0.81     0.0000   16\n",
       "2011-01-01 01:00:00        0           1  0.22  0.2727  0.80     0.0000   40\n",
       "2011-01-01 02:00:00        0           1  0.22  0.2727  0.80     0.0000   32\n",
       "2011-01-01 03:00:00        0           1  0.24  0.2879  0.75     0.0000   13\n",
       "2011-01-01 04:00:00        0           1  0.24  0.2879  0.75     0.0000    1\n",
       "2011-01-01 05:00:00        0           2  0.24  0.2576  0.75     0.0896    1\n",
       "2011-01-01 06:00:00        0           1  0.22  0.2727  0.80     0.0000    2\n",
       "2011-01-01 07:00:00        0           1  0.20  0.2576  0.86     0.0000    3\n",
       "2011-01-01 08:00:00        0           1  0.24  0.2879  0.75     0.0000    8\n",
       "2011-01-01 09:00:00        0           1  0.32  0.3485  0.76     0.0000   14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-01 01:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-01 02:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-01 03:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-01 04:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-01 05:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-01 06:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-01 07:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-01 08:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-01 09:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.2537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     holiday  weathersit  temp   atemp   hum  windspeed\n",
       "date_hour                                                              \n",
       "2012-12-01 00:00:00        0           1  0.26  0.3030  0.81     0.0000\n",
       "2012-12-01 01:00:00        0           1  0.26  0.3030  0.81     0.0000\n",
       "2012-12-01 02:00:00        0           2  0.26  0.3030  0.81     0.0000\n",
       "2012-12-01 03:00:00        0           2  0.26  0.2727  0.81     0.1343\n",
       "2012-12-01 04:00:00        0           1  0.26  0.2879  0.81     0.0896\n",
       "2012-12-01 05:00:00        0           1  0.24  0.2576  0.87     0.0896\n",
       "2012-12-01 06:00:00        0           1  0.24  0.2424  0.87     0.1343\n",
       "2012-12-01 07:00:00        0           2  0.24  0.2424  0.87     0.1343\n",
       "2012-12-01 08:00:00        0           2  0.24  0.2424  0.87     0.1343\n",
       "2012-12-01 09:00:00        0           2  0.26  0.2424  0.93     0.2537"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train and Test data\n",
    "display(train.head(10), test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_hour</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-01 00:00:00</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-12-01 01:00:00</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-12-01 02:00:00</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-01 03:00:00</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-01 04:00:00</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-12-01 05:00:00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012-12-01 06:00:00</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012-12-01 07:00:00</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-12-01 08:00:00</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012-12-01 09:00:00</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_hour  cnt\n",
       "0  2012-12-01 00:00:00  784\n",
       "1  2012-12-01 01:00:00   80\n",
       "2  2012-12-01 02:00:00  605\n",
       "3  2012-12-01 03:00:00  604\n",
       "4  2012-12-01 04:00:00  544\n",
       "5  2012-12-01 05:00:00  100\n",
       "6  2012-12-01 06:00:00  344\n",
       "7  2012-12-01 07:00:00   18\n",
       "8  2012-12-01 08:00:00   57\n",
       "9  2012-12-01 09:00:00  603"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample submission for kaggle\n",
    "display(sample_submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seizoenspatronen met Fourier analyse\n",
    "\n",
    "### Wat is Fourier analyse?\n",
    "Het is een wiskundig methode dat patronen vindt binnen een genormaliseerde timeseries dataset. Het vereenvoudigt complexe data door het te veranderen naar een serie van trigonomische of exponentiele functies. Door alle complicerende factors van het dataset weg te halen kunnen patronen makkelijker herkend worden, waardoor voorspellingen maken makkelijker wordt.\n",
    "\n",
    "[(Hayes, 2023)](https://www.investopedia.com/terms/f/fourieranalysis.asp) \n",
    "\n",
    "De formule van een Fourier series:\n",
    "$$\n",
    "f(t) = \\frac{a_0}{2} + \\sum_{k=1}^{\\infty}(a_k\\cos(2\\pi kt) + b_k\\sin(2\\pi kt))\n",
    "$$\n",
    "\n",
    "waar\n",
    "- $\\frac{a_0}{2}$ het constante term representeert,\n",
    "- $a_k\\cos(2\\pi kt)$ en $b_k\\sin(2\\pi kt)$ de cosinus en sinus termen zijn,\n",
    "- $k$ het harmonische frequentie is,\n",
    "- $\\sum_{k=1}^{\\infty}$ zegt dat er een oneindig serie van sinus en cosinus functies met verschillende frequenties en amplitudes opgeteld worden, die $f(t)$ preciezer zou vinden\n",
    "\n",
    "Een fourier analyse is het manier waarop functies benaderd kunnen worden door het combinatie van trigonometrische functies. \n",
    "\n",
    "[(3Blue1Brown, 2018)](https://www.youtube.com/watch?v=spUNpyF58BY )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de visualisaties is het te zien dat de target variabele begint toe te nemen rond april, en afneemt rond de wintermaanden, beginnend met november."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onderzoek naar trends\n",
    "\n",
    "Na een Fourier analyse uit te voeren op de data, is het te zien dat de grootste trends jaarlijks en dagelijks zijn. De jaarlijkse trends zou in dit geval groei van het populariteit van het product over tijd kunnen zijn, dit ligt aan het feit dat de jaarlijkse piek in 2011 lager is dan die van 2012.\n",
    "\n",
    "De dagelijkse trend kan liggen aan andere variabelen, zoals temperatuur, weeromstandigheden of vakantie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ts_fe.X_train.copy()\n",
    "y_train = ts_fe.y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Regression\n",
    "\n",
    "De KNN algoritme is een techniek die zich richt op de waardes rond een bepaald punt. Die punt wordt dan geclassificeerd op basis van het aantal ingestelde 'nearest neighbors', oftewel naaste buren. Als je dan instelt dat je de 5 'nearest neighbors' kiest, dan wordt de waarde geclassificeerd als de meerderheid van die buren. \n",
    "\n",
    "[(IBM, 2024)](https://www.ibm.com/topics/knn)\n",
    "\n",
    "KNN Regression is een eenvoudig algoritme dat gebaseerd is op het afstand van een punt tot een bepaald aantal dichtbijzijnde punten (K). Het afstand kan op een aantal verschillende manieren gemeten worden. Ten opzichte van KNN-classificatie, in KNN-regressie is de voorspelde waarde van de datapunt gelijk aan de gemiddelde van de dichtbijzijnde punten \n",
    "(target-waardes).\n",
    "\n",
    "[(Singh, 2024)](https://www.analyticsvidhya.com/blog/2018/08/k-nearest-neighbor-introduction-regression-python/#How_Does_the_KNN_Algorithm_Work?)\n",
    "\n",
    "De afstand naar de gekozen punt wordt meestal berekent met de manhattan- of euclidean-methode. De **Euclidean** methode berekent een rechte lijn tussen de gekozen punt en een 'buur'. Euclidean afstand bereken je met de volgende formule:\n",
    "\n",
    "$$\n",
    "d(x, y) = \\sqrt{\\sum_{i=1}^{n} (y_i - x_i)^2}\n",
    "$$\n",
    "\n",
    "De **Manhattan** methode kiest voor het meten van de absolute waarde van het verschil tussen twee punten. De naam komt van de visualisatie die vaak met dit methode komt, omdat het als een rooster uitziet, net alsof je Manhattan van boven ziet. De Manhattan afstand kun je berekenen met dit methode:\n",
    "\n",
    "$$\n",
    "d(x, y) = (\\sum_{i=1}^{m} |x_i - y_i|)\n",
    "$$\n",
    "\n",
    "[(IBM, 2024)](https://www.ibm.com/topics/knn)\n",
    "\n",
    "**Standardisatie**\n",
    "\n",
    "De manier waarop KNN beslissingen neemt heeft veel te maken met het afstand tussen waardes, waardoor de schaal veel invloed heeft op de afstandsbepaling. Door de waardes te standardiseren, voorkom je dat sommige features meer voorkomen.\n",
    "\n",
    "[(Goedegebuure, 2021)](https://bookdown.org/robert_statmind/mmsc_test_01/the-k-nn-algorithm.html#standardizing-data)\n",
    "\n",
    "**Hyperparameters**\n",
    "\n",
    "De belangrijkste hyperparameter bij KNN is de het aantal buren (k). Een grotere k-waarde geeft een eenvoudige decision-boundary en vermindert overfitting, maar is niet handig met alle datasets. Een kleinere k-waarde kan er juist voor zorgen dat er sprake is van overfitting. \n",
    "\n",
    "[(Abdallah, 2023)](https://www.linkedin.com/pulse/improve-model-hyperparameter-tuning-k-nearest-muctary-abdallah-1e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daadwerkelijke KNN model\n",
    "\n",
    "knn_model = KNeighborsRegressor(n_neighbors=3, weights='distance', metric='manhattan')\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "knn_score = cross_val_score(knn_model, X_train, y_train, scoring='neg_root_mean_squared_error', cv=10, n_jobs=-1, verbose=1).mean()\n",
    "print(f\"KNN score: {knn_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beste parameters\n",
    "\n",
    "knn_param = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "knn_model = KNeighborsRegressor()\n",
    "grid_search = GridSearchCV(knn_model, knn_param, cv=10, scoring='neg_root_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Beste parameters: {grid_search.best_params_}\")\n",
    "\n",
    "knn_tuned = grid_search.best_estimator_\n",
    "knn_score = cross_val_score(knn_model, X_train, y_train, scoring='neg_root_mean_squared_error', cv=10, n_jobs=-1, verbose=1).mean()\n",
    "print(f\"KNN score: {knn_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression\n",
    "\n",
    "Een SVR model heeft als doel het voorspellen van een continu waarde, waar de waarde binnen de tolerantie-grens ϵ moet liggen van de correcte waarde. Alle voorspellingen die buiten dit grens liggen worden gepenaliseerd.\n",
    "\n",
    "De SVR model kan ook non-lineaire relaties vinden met zijn **kernel-trick functie**. Hiermee krijgt de model een extra dimensie dat complexe relaties kan onderscheiden.\n",
    "\n",
    "[(Sethi, 2024)](https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/)\n",
    "\n",
    "### SVR model bij een lineaire relatie\n",
    "\n",
    "$$\n",
    "w*x+b = y\n",
    "$$\n",
    "\n",
    "- $w$ : vector die de helling van de lijn of hypervlak bepaalt\n",
    "- $x$ : invoerpunt\n",
    "- $b$ : bias-term, oftewel het afstand vanaf het oorsprong langs het normaalvector $w$\n",
    "- $y$ : de optimale hypervlak\n",
    "\n",
    "Een SVR wil in dit geval aan het conditie $-a < y-wx+b < a$ te voldoen, waar $a$ het beste lijn binnen de grenswaarde is. De punten binnen de grens worden gebruikt om de waarde te voorspellen.\n",
    "\n",
    "[(Gurucharan, 2020)](https://towardsdatascience.com/machine-learning-basics-support-vector-regression-660306ac5226)\n",
    "\n",
    "### Afstand en de tolerantie-grens ϵ\n",
    "\n",
    "$$\n",
    "d_{i} = |y_i - (w^tx_i + b)|\n",
    "$$\n",
    "\n",
    "- $d_{i}$ : de absolute afwijking tussen de voorspelling en de daadwerkelijke waarde\n",
    "- ϵ : de tolerantie-grens, oftewel de maximaal toegestane afwijking dat nog goed wordt gekeurd/geen penalty krijgt\n",
    "\n",
    "Voor alle punten waar $d_i$ > ϵ geldt, wordt er een penalty gegeven. De penalty wordt gegeven volgens de **loss-functie**.\n",
    "\n",
    "### Kernel trick\n",
    "\n",
    "De kernel-trick is een techniek dat gebruikt wordt bij het toepassen van de SVR algoritme, dat niet-lineair-verdeelbare data neemt en dat omzet tot in een hoger dimensie waar de data wel lineair verdeelbaar is.\n",
    "\n",
    "[(Yadav, 2023)](https://medium.com/@Suraj_Yadav/what-is-kernel-trick-in-svm-interview-questions-related-to-kernel-trick-97674401c48d)\n",
    "\n",
    "### Loss functie\n",
    "\n",
    "De loss functie van SVR wordt de lineair epsilon-insensitive loss genoemd. Hier is de loss gemeten door het afstand te bepalen tussen de gekozen waarde $y$ en de $\\epsilon$ tolerantiegrens. De wiskundige notatie van de loss function:\n",
    "\n",
    "$$\n",
    "L_{\\epsilon} =\n",
    "\\begin{cases} 0, & \\text{als } |y - f(x)| \\leq \\epsilon \\\\\n",
    "|y - f(x)| - \\epsilon, & \\text{anders} \\end{cases}\n",
    "$$\n",
    "\n",
    "- $y$ : De ware classificatie voor de datapunt\n",
    "- $f(x)$ : Het voorspelde waarde van de datapunt\n",
    "\n",
    "[(Mathworks, z.d.)](https://nl.mathworks.com/help/stats/understanding-support-vector-machine-regression.html)\n",
    "\n",
    "### Regularisatie\n",
    "\n",
    "De manier van regularisatie in de Support Vector Regression werkt voornamelijk met het regularisatie parameter C. Dit parameter controleert de afwisseling tussen het negatieve correlatie met het maximaliseren van de marge en het minimaliseren van fouten bij het voorspelling. \n",
    "\n",
    "**Hyperparameters**\n",
    "- C, het regularisatie parameter\n",
    "- epsilon/$\\epsilon$, de tolerantie-grens \n",
    "- gamma, het kernel-coefficient\n",
    "- kernel, de keuze van kernel\n",
    "\n",
    "[(Van Otten, 2024)](https://spotintelligence.com/2024/05/08/support-vector-regression-svr/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daadwerkelijke model\n",
    "\n",
    "svm_model = SVR(C=100, epsilon=0.001, gamma=0.1, kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "svm_score = cross_val_score(svm_model, X_train, y_train, scoring='neg_root_mean_squared_error', cv=10, n_jobs=-1, verbose=1).mean()\n",
    "print(f\"SVM score: {svm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Beste parameters\u001b[39;00m\n\u001b[1;32m      3\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m],\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m---> 10\u001b[0m svm_model \u001b[38;5;241m=\u001b[39m \u001b[43mSVR\u001b[49m()\n\u001b[1;32m     11\u001b[0m svmgrid \u001b[38;5;241m=\u001b[39m GridSearchCV(svm_model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_root_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m svmgrid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SVR' is not defined"
     ]
    }
   ],
   "source": [
    "# Beste parameters\n",
    "\n",
    "param_grid = {\n",
    "    'kernel': ['rbf'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'epsilon': [0.001, 0.01, 0.1, 1],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1, 10, 100],\n",
    "}\n",
    "\n",
    "svm_model = SVR()\n",
    "svmgrid = GridSearchCV(svm_model, param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "svmgrid.fit(X_train, y_train)\n",
    "print(f\"Beste parameters: {svmgrid.best_params_}\")\n",
    "\n",
    "svm_tuned = grid_search.best_estimator_\n",
    "svm_score = cross_val_score(svm_tuned, X_train, y_train, scoring='neg_root_mean_squared_error', cv=10, n_jobs=-1, verbose=1).mean()\n",
    "print(f\"SVM score: {svm_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "#### KNN\n",
    "De KNN Regressor is heel snel, maar scoort niet goed met de dataset, zelfs met optimale hyperparameters. Dit komt waarschijnlijk omdat het model best eenvoudig werkt, waardoor het niet goed omgaat met time-series data. \n",
    "\n",
    "#### Linear Regression\n",
    "Het model heeft een snelle runtijd, maar de scoren zijn niet goed. Na het toepassen van grid search met verschillende hyperparameters blijft de score bijna hetzelfde. Ook het gebruik van regularisatie heeft niet veel geholpen om de score van het model te verbeteren.\n",
    "\n",
    "#### Decision Tree\n",
    "Het model heeft een hele korte runtijd en scoort overigens ook best goed. Optimale hyperparameters met behulp van grid search gevonden. Met random forest zou het mogelijk zijn om de voorspellingen nauwkeuriger te maken en de score te verbeteren.\n",
    "\n",
    "#### SVR\n",
    "De linear en poly kernels leiden tot een hele lange runtijd, dus het vinden van optimale hyperparameters bij deze kernels met grid search zou onmogelijk lang duren. Verder, door het ontwerp van SVR is het ook niet praktisch om met grote (time-series) datasets te werken. Hierdoor heeft de model laag gescoord.\n",
    "\n",
    "#### Random Forest\n",
    "Het model neemt lang door de optimale hyperparameters van grid search, maar heeft een beter score gehaald dan de enkele Decision Tree. \n",
    "\n",
    "#### Gradient Boost\n",
    "Het neemt werkelijk meer tijd om te trainen. Na een keer runnen, overgestapt naar XGBoost en bepaalde parameters voor gridsearch aangepast bij Gradient Boost.\n",
    "\n",
    "#### XGBoost\n",
    "Na een keer gridsearch runnen, dan handmatig wat waardes voor de parameters testen die niet voor gridsearch werd gebruikt. Kwam wat parameters tegen die het model een klein beetje beter heeft kunnen maken.\n",
    "\n",
    "#### AdaBoost\n",
    "Na een keer gridsearch runnen, ook handmatig getest en weer gridsearch. De score is niet zo goed als van XGBoost. Het kan zijn doordat hoe Ada werkt met moeilijkere voorspellingen.\n",
    "\n",
    "#### Stacking\n",
    "\n",
    "#### SARIMA(X)\n",
    "\n",
    "#### Prophet\n",
    "\n",
    "#### Hybrid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De Root Mean Squared Error (RMSE) scores worden in dit tabel genoteerd. Als er betere scores zijn op kaggle, dan komt het doordat de submission gedaan werd na het inleveren van de opdracht en/of er veranderingen zijn gebracht in feature engineering en niet genoeg tijd over is om alle modellen te hertrainen.\n",
    "\n",
    "|Model              |Notebook Score|Kaggle Score|\n",
    "|-------------------|--------------|------------|\n",
    "|KNN                |147.76        |0           |\n",
    "|Logistic Regression|125.42        |0           |\n",
    "|Decision Tree      |0             |0           |\n",
    "|SVR                |138.88        |0           |\n",
    "|Random Forest      |0             |0           |\n",
    "|Gradient Boost     |52.88         |0           |\n",
    "|XGBoost            |50.71         |0           |\n",
    "|AdaBoost           |103.00        |0           |\n",
    "|Stacking           |54.38         |0           |\n",
    "|SARIMA(X)          |0             |0           |\n",
    "|Prophet            |0             |0           |\n",
    "|hybride model      |0             |0           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion & Advice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3Blue1Brown. (2018, 26 januari). But what is the Fourier Transform?  A visual introduction. [Video]. YouTube. https://www.youtube.com/watch?v=spUNpyF58BY\n",
    "\n",
    "- Abdallah, M. (2023, 2 mei). Improve model - Hyperparameter tuning in k-nearest neighbors. https://www.linkedin.com/pulse/improve-model-hyperparameter-tuning-k-nearest-muctary-abdallah-1e\n",
    "\n",
    "- Goedegebuure, R. (2021, 8 februari). Chapter 3 The K-NN Algorithm | Market Segmentation & Clustering. https://bookdown.org/robert_statmind/mmsc_test_01/the-k-nn-algorithm.html#standardizing-data\n",
    "\n",
    "- Gurucharan, M. K. (2021, 15 december). Machine Learning Basics: support vector regression - towards data science. Medium. https://towardsdatascience.com/machine-learning-basics-support-vector-regression-660306ac5226\n",
    "\n",
    "- Hayes, A. (2023, 4 juli). Fourier Analysis: What it Means, How it Works. Investopedia. https://www.investopedia.com/terms/f/fourieranalysis.asp\n",
    "\n",
    "- IBM. (2024, 28 oktober). KNN. IBM. https://www.ibm.com/topics/knn\n",
    "\n",
    "- Mathworks. (z.d.). Understanding support vector machine regression. https://nl.mathworks.com/help/stats/understanding-support-vector-machine-regression.html\n",
    "\n",
    "- Sethi, A. (2024, 20 november). Support Vector Regression Tutorial for Machine Learning. Analytics Vidhya. https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/\n",
    "\n",
    "- Singh, A. (2024, 8 oktober). KNN algorithm: Introduction to K-Nearest Neighbors Algorithm for Regression. Analytics Vidhya. https://www.analyticsvidhya.com/blog/2018/08/k-nearest-neighbor-introduction-regression-python/#How_Does_the_KNN_Algorithm_Work?\n",
    "\n",
    "- Van Otten, N. (2024, 11 oktober). Support Vector Regression (SVR) Simplified & How To Tutorial In Python. Spot Intelligence. https://spotintelligence.com/2024/05/08/support-vector-regression-svr/\n",
    "\n",
    "- Yadav, S. (2023, 30 april). What is Kernel Trick in SVM ? Interview questions related to Kernel Trick. Medium. https://medium.com/@Suraj_Yadav/what-is-kernel-trick-in-svm-interview-questions-related-to-kernel-trick-97674401c48d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
